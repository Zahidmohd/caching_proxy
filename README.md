# Caching Proxy Server

A production-ready, feature-rich HTTP caching proxy server built with Node.js. This high-performance CLI tool intelligently forwards requests to origin servers, caches responses, and serves subsequent requests instantly from cache - complete with a real-time web dashboard for monitoring.

> **Built from scratch** to understand HTTP caching mechanisms, proxy architecture, and modern web development practices.

## âœ¨ Key Features

### Core Caching
- âš¡ **Lightning Fast** - Cache HIT responses in <5ms (vs 100-500ms origin requests)
- ğŸ’¾ **Smart Caching** - Intelligent cache policies respecting HTTP standards
- ğŸ”„ **Cache Headers** - Clear `X-Cache: HIT/MISS/REVALIDATED` indicators
- ğŸ“¦ **Persistent Storage** - File-based cache survives server restarts
- ğŸ—‘ï¸ **LRU Eviction** - Automatic memory management with configurable limits
- â±ï¸ **Configurable TTL** - Pattern-based TTL rules for different endpoints

### Advanced Features
- ğŸ”‘ **Header-Based Keys** - Cache variants by Accept-Language, User-Agent, etc.
- ğŸ—œï¸ **Response Compression** - Gzip/Brotli compression for optimized storage
- ğŸ”„ **Conditional Requests** - ETag/Last-Modified support with 304 responses
- ğŸš¦ **Rate Limiting** - IP-based rate limiting with whitelist/blacklist
- ğŸŒ **Multi-Origin Routing** - Path-based routing to multiple backend services
- ğŸ” **HTTPS Support** - Full SSL/TLS with dual HTTP/HTTPS mode
- ğŸ”Œ **Plugin System** - Extensible architecture with lifecycle hooks
- ğŸ¯ **Cache Versioning** - API version-specific cache isolation
- ğŸ”§ **Request Transformation** - Custom request/response modification hooks

### Monitoring & Management
- ğŸ“Š **Web Dashboard** - Real-time visual monitoring interface
- ğŸ“ˆ **Analytics** - Detailed metrics on cache performance and bandwidth savings
- ğŸ¥ **Health Checks** - Origin server health monitoring
- ğŸ“ **Advanced Logging** - Structured logging with rotation
- ğŸ”¥ **Cache Warming** - Pre-populate cache from URL lists
- ğŸ¯ **Flexible Invalidation** - Pattern-based, URL-specific, time-based cache clearing

## ğŸ“¦ Installation

### Prerequisites
- Node.js v14 or higher
- npm (comes with Node.js)

### Quick Start

```bash
# Clone the repository
git clone <your-repo-url>
cd caching-proxy

# Install dependencies
npm install

# Make it globally available
npm link

# Start the proxy server
caching-proxy --port 3000 --origin https://dummyjson.com
```

### Alternative: Run Without Global Install

```bash
# Clone and install
git clone <your-repo-url>
cd caching-proxy
npm install

# Run directly
node src/index.js --port 3000 --origin https://dummyjson.com
```

## ğŸš€ Quick Usage Examples

### Example 1: Basic Usage

```bash
# Start the proxy
caching-proxy --port 3000 --origin https://dummyjson.com

# In another terminal, make requests
curl http://localhost:3000/products/1        # MISS - fetches from origin
curl http://localhost:3000/products/1        # HIT - serves from cache

# Clear cache when needed
caching-proxy --clear-cache
```

### Example 2: With Web Dashboard

```bash
# Start proxy with real-time dashboard
caching-proxy --port 3000 --origin https://dummyjson.com --dashboard 4000

# Open http://localhost:4000 in your browser
# See live metrics, manage cache, view performance stats
```

**Dashboard Features**:
- ğŸ“Š Real-time metrics with auto-refresh (every 5 seconds)
- ğŸ¨ Modern dark theme UI with smooth animations
- ğŸ” Search and filter cached URLs
- ğŸ—‘ï¸ Interactive cache management (delete/clear)
- ğŸ“ˆ Performance charts and bandwidth savings
- ğŸ¥ Origin server health monitoring

### Example 3: Using Configuration File

```bash
# Create config file
cat > proxy.config.json << EOF
{
  "server": {
    "port": 3000,
    "origin": "https://dummyjson.com",
    "dashboardPort": 4000
  },
  "cache": {
    "defaultTTL": 300,
    "maxEntries": 1000,
    "maxSizeMB": 100,
    "cacheKeyHeaders": ["accept-language"]
  },
  "logging": {
    "level": "info",
    "format": "text"
  }
}
EOF

# Start with config
caching-proxy --config proxy.config.json
```

### Example 4: Cache Warming

```bash
# Create a file with URLs to pre-fetch
cat > warm-urls.txt << EOF
/products/1
/products/2
/users/1
/categories
EOF

# Warm the cache
caching-proxy --warm-cache warm-urls.txt --origin https://dummyjson.com
```

### Example 5: Advanced Cache Management

```bash
# View cache statistics
caching-proxy --cache-stats

# List all cached URLs
caching-proxy --cache-list

# Clear cache by pattern
caching-proxy --clear-cache-pattern "/products/*"

# Clear cache older than 1 hour
caching-proxy --clear-cache-older-than 1h

# Preview what would be deleted (dry-run)
caching-proxy --clear-cache-pattern "/api/*" --dry-run
```

## ğŸ”§ How It Works

### Request Flow

```
1. Client Request â†’ Proxy Server
2. Proxy checks cache
   â”œâ”€ Cache HIT?  â†’ Return cached response with X-Cache: HIT
   â””â”€ Cache MISS? â†’ Forward to origin
                   â†’ Receive response
                   â†’ Add X-Cache: MISS header
                   â†’ Return to client
                   â†’ Store in cache (if cacheable)
```

### Caching Strategy

**What Gets Cached:**
- âœ… Only **GET requests** (standard HTTP practice)
- âœ… Only successful responses (status codes 200-299)
- âœ… Only **non-authenticated** requests (no Authorization header or cookies)
- âœ… Only when origin allows (respects Cache-Control headers)
- âœ… Complete response: status code, headers, and body
- âœ… With **5-minute TTL by default** (configurable)
- âœ… Query parameters are part of the cache key
- âœ… Optional header-based cache keys for content negotiation

**What Doesn't Get Cached:**
- âŒ Non-GET methods (POST, PUT, DELETE, PATCH, etc.)
- âŒ Authenticated requests (Authorization header or cookies present)
- âŒ Responses with `Cache-Control: no-store`, `no-cache`, or `private`
- âŒ Client errors (4xx) and server errors (5xx)
- âŒ Redirects (3xx)
- âŒ Expired entries

### Cache Key Format

```
Basic: METHOD:URL
Examples:
- GET:https://dummyjson.com/products/1
- GET:https://dummyjson.com/products?limit=10

With Headers: METHOD:URL:HEADER_HASH
Examples:
- GET:https://api.com/data:a1b2c3d4 (with Accept-Language: en-US)
- GET:https://api.com/data:x9y8z7w6 (with Accept-Language: fr-FR)
```

### LRU (Least Recently Used) Eviction

The cache automatically manages its size to prevent unlimited growth:

**How It Works:**
1. Each cache entry tracks its `lastAccessTime`
2. When cache exceeds limits (entries or size), oldest entries are evicted
3. Eviction targets 90% of limits to avoid constant cleanup
4. All eviction events are logged to `logs/cache.log`

**Default Limits:**
- **Max Entries**: 1,000 cache entries
- **Max Size**: 100 MB total cache size

**Configuration:**
```json
{
  "cache": {
    "maxEntries": 1000,
    "maxSizeMB": 100
  }
}
```

## âš™ï¸ Configuration

### Command-Line Arguments

| Argument | Description | Example |
|----------|-------------|---------|
| `--port <number>` | Port for proxy server | `--port 3000` |
| `--origin <url>` | Origin server URL | `--origin https://api.com` |
| `--config <path>` | Load configuration from file | `--config proxy.config.json` |
| `--dashboard <port>` | Start web dashboard on specified port | `--dashboard 4000` |
| `--clear-cache` | Clear all cached entries | `--clear-cache` |
| `--clear-cache-pattern <pattern>` | Clear cache matching URL pattern | `--clear-cache-pattern "/api/*"` |
| `--clear-cache-url <url>` | Clear specific cached URL | `--clear-cache-url "https://api.com/data"` |
| `--clear-cache-older-than <time>` | Clear entries older than time | `--clear-cache-older-than 1h` |
| `--dry-run` | Preview deletions without deleting | `--clear-cache --dry-run` |
| `--warm-cache <file>` | Pre-populate cache with URLs from file | `--warm-cache urls.txt` |
| `--cache-stats` | Display cache statistics | `--cache-stats` |
| `--cache-list` | List all cached URLs | `--cache-list` |
| `--log-level <level>` | Set log level (debug/info/warn/error) | `--log-level debug` |
| `--help` | Show help message | `--help` |
| `--version` | Show version number | `--version` |

### Configuration File Options

**Basic Configuration:**
```json
{
  "server": {
    "port": 3000,
    "origin": "https://api.example.com",
    "dashboardPort": 4000
  },
  "cache": {
    "defaultTTL": 300,
    "maxEntries": 1000,
    "maxSizeMB": 100,
    "cacheKeyHeaders": ["accept-language", "accept-encoding"],
    "compression": {
      "enabled": true,
      "method": "gzip"
    }
  },
  "logging": {
    "level": "info",
    "format": "text"
  }
}
```

**Advanced Configuration:**
```json
{
  "server": {
    "port": 3000,
    "origin": "https://api.example.com",
    "dashboardPort": 4000,
    "https": {
      "enabled": true,
      "certPath": "./certs/server.crt",
      "keyPath": "./certs/server.key"
    }
  },
  "cache": {
    "defaultTTL": 300,
    "maxEntries": 5000,
    "maxSizeMB": 500,
    "cacheKeyHeaders": ["accept-language", "user-agent"],
    "patternTTL": {
      "/api/products/*": 600,
      "/api/users/*": 300,
      "/api/static/**": 3600
    }
  },
  "security": {
    "rateLimit": {
      "enabled": true,
      "requestsPerMinute": 100,
      "requestsPerHour": 1000
    }
  }
}
```

### Header-Based Cache Keys

Configure headers to include in cache keys for content negotiation:

```json
{
  "cache": {
    "cacheKeyHeaders": ["accept-language", "accept-encoding"]
  }
}
```

**Common Use Cases:**
- **Internationalization**: `["accept-language"]` - Cache by language (en-US, fr-FR, etc.)
- **Content Negotiation**: `["accept-encoding"]` - Cache by encoding (gzip, brotli)
- **Device Differentiation**: `["user-agent"]` - Separate cache for mobile/desktop
- **API Versioning**: `["x-api-version"]` - Cache by version (v1, v2, v3)
- **Multi-Tenant**: `["x-tenant-id"]` - Separate cache per tenant

**Automatic Vary Header Support:**

The proxy automatically respects the `Vary` header from origin responses:
- Parses varying headers (e.g., `Vary: Accept-Language`)
- Merges with configured `cacheKeyHeaders`
- Stores separate cache entries for different header combinations

## ğŸ—‚ï¸ Project Structure

```
caching-proxy/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js          # CLI entry point
â”‚   â”œâ”€â”€ cli.js            # Command handlers
â”‚   â”œâ”€â”€ server.js         # Proxy server
â”‚   â”œâ”€â”€ cache.js          # Cache management
â”‚   â”œâ”€â”€ analytics.js      # Analytics & metrics
â”‚   â”œâ”€â”€ logger.js         # Logging system
â”‚   â”œâ”€â”€ config.js         # Configuration loader
â”‚   â”œâ”€â”€ dashboard.js      # Web dashboard server
â”‚   â”œâ”€â”€ router.js         # Multi-origin routing
â”‚   â”œâ”€â”€ rateLimit.js      # Rate limiting
â”‚   â”œâ”€â”€ healthCheck.js    # Health monitoring
â”‚   â”œâ”€â”€ versionManager.js # Cache versioning
â”‚   â”œâ”€â”€ transformations.js# Request/response transforms
â”‚   â””â”€â”€ pluginManager.js  # Plugin system
â”œâ”€â”€ public/               # Dashboard UI files
â”‚   â”œâ”€â”€ index.html        # Dashboard HTML
â”‚   â”œâ”€â”€ dashboard.css     # Dashboard styles
â”‚   â””â”€â”€ dashboard.js      # Dashboard JavaScript
â”œâ”€â”€ cache/                # Cache storage (auto-generated)
â”œâ”€â”€ logs/                 # Log files (auto-generated)
â”œâ”€â”€ docs/                 # Documentation guides
â”‚   â”œâ”€â”€ TESTING.md        # Test documentation
â”‚   â”œâ”€â”€ CONFIG_DOCUMENTATION.md  # Configuration guide
â”‚   â””â”€â”€ PLUGIN_DEVELOPMENT.md    # Plugin development guide
â”œâ”€â”€ proxy.config.json     # Example configuration
â”œâ”€â”€ package.json          # Dependencies & scripts
â””â”€â”€ README.md             # This file
```

## ğŸ§ª Testing

### Manual Testing

```bash
# Start the server
caching-proxy --port 3000 --origin https://dummyjson.com

# Test cache MISS (first request)
curl -i http://localhost:3000/products/1
# Look for: x-cache: MISS

# Test cache HIT (second request)
curl -i http://localhost:3000/products/1
# Look for: x-cache: HIT

# Test with query parameters
curl http://localhost:3000/products?limit=5

# Clear cache and verify
caching-proxy --clear-cache
curl -i http://localhost:3000/products/1  # Should be MISS again
```

### Comprehensive Testing

See [TESTING.md](docs/TESTING.md) for detailed test documentation covering:
- CLI argument parsing
- HTTP server functionality
- Request forwarding
- Caching mechanisms
- Cache headers and invalidation
- Performance benchmarks

**Total: 85+ documented test cases**

## ğŸš¨ Troubleshooting

### Port Already in Use

**Error:** `Port 3000 is already in use`

**Solution:**
```bash
# Option 1: Use a different port
caching-proxy --port 8080 --origin https://dummyjson.com

# Option 2: Kill the process (Windows)
netstat -ano | findstr :3000
taskkill /PID <PID> /F

# Option 2: Kill the process (Linux/Mac)
lsof -ti:3000 | xargs kill -9
```

### Invalid Origin URL

**Error:** `Invalid origin URL`

**Solution:** Ensure the origin URL includes the protocol:
```bash
# âŒ Wrong
caching-proxy --port 3000 --origin dummyjson.com

# âœ… Correct
caching-proxy --port 3000 --origin https://dummyjson.com
```

### Requests Not Being Cached

**Possible Causes:**
1. Non-2xx status code - Only 200-299 responses are cached
2. Authenticated request - Requests with Authorization header are not cached
3. Origin sends `Cache-Control: no-store` - Respecting HTTP caching directives
4. Non-GET method - Only GET requests are cached by default

**Check:** Look at server logs for `ğŸ’¾ Cached:` or `â­ï¸ NOT cached` messages

### Connection Errors

**Error:** `Bad Gateway: Unable to reach origin server`

**Solution:** Verify origin server is accessible:
```bash
curl https://dummyjson.com/products/1
```

## ğŸ“Š Performance Notes

### Cache Performance
- **Cache HIT**: ~1-5ms response time (instant, no network call)
- **Cache MISS**: Depends on origin server response time
- **Speedup**: Typically 50-100x faster for cached responses
- **Storage**: File-based, persists across server restarts
- **Memory**: Minimal - cache stored on disk

### Scalability
- **Concurrent Requests**: Node.js handles multiple simultaneous requests
- **Cache Size**: Limited only by configured limits and disk space
- **File I/O**: Optimized for read/write operations

### Best Practices
1. **Use for Read-Heavy APIs** - Maximum benefit for GET requests
2. **Configure Appropriate TTL** - Balance freshness vs performance
3. **Monitor Cache Size** - Use `--cache-stats` regularly
4. **Set Reasonable Limits** - Based on your server's resources
5. **Use Dashboard** - Monitor performance in real-time

## ğŸ“š Additional Documentation

- **[CONFIG_DOCUMENTATION.md](docs/CONFIG_DOCUMENTATION.md)** - Complete configuration reference with environment variable support
- **[PLUGIN_DEVELOPMENT.md](docs/PLUGIN_DEVELOPMENT.md)** - Plugin system architecture and development guide
- **[TESTING.md](docs/TESTING.md)** - Comprehensive testing documentation and procedures

## ğŸ› ï¸ Tech Stack

- **Runtime**: Node.js (v14+)
- **Language**: JavaScript (ES6+)
- **Dependencies**:
  - `commander` (v11.1.0) - CLI argument parsing
  - Node.js built-in modules: `http`, `https`, `fs`, `path`, `crypto`, `zlib`

## ğŸ’¡ What I Learned

Building this project from scratch taught me:

- **HTTP Protocol**: Deep understanding of HTTP methods, headers, status codes, caching headers (ETag, Cache-Control, Vary), and conditional requests
- **Proxy Architecture**: Request forwarding, header preservation, response streaming, and error handling patterns
- **Caching Strategies**: LRU eviction algorithms, TTL management, cache invalidation patterns, and compression techniques
- **Node.js**: HTTP/HTTPS modules, streams, file I/O, event-driven architecture, and async programming
- **Production Practices**: Structured logging, health monitoring, rate limiting, graceful error handling, and deployment considerations
- **Web Development**: Real-time dashboard with vanilla JavaScript, CSS animations, responsive design, and REST API design
- **Software Architecture**: Modular design patterns, plugin systems, configuration management, and separation of concerns

## ğŸš€ Why This Project?

This caching proxy was built as a comprehensive learning project to understand:
- How CDNs and reverse proxies work under the hood
- HTTP caching mechanisms and best practices
- Building production-ready Node.js applications
- System design for scalable backend services

The project evolved from a simple proxy server to a feature-complete caching solution with 27 production-ready features, demonstrating progressive enhancement and iterative development.

## ğŸ“Š Project Statistics

- **Total Features**: 27 comprehensive features
- **Lines of Code**: ~7,000+ (excluding tests and documentation)
- **Architecture**: Modular design with 15+ separate modules
- **Test Coverage**: 85+ documented test cases
- **Production Ready**: Complete error handling, logging, and monitoring

## ğŸ¤ Contributing

Contributions are welcome! To contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Commit your changes (`git commit -m 'Add amazing feature'`)
5. Push to the branch (`git push origin feature/amazing-feature`)
6. Open a Pull Request

## ğŸ“„ License

ISC

## ğŸ”— Resources

- [HTTP Caching - MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching)
- [HTTP Proxy - Wikipedia](https://en.wikipedia.org/wiki/Proxy_server#Web_proxy_servers)
- [Node.js HTTP Module](https://nodejs.org/api/http.html)
- [RFC 7234 - HTTP Caching](https://tools.ietf.org/html/rfc7234)
- [Project Idea](https://roadmap.sh/projects/caching-server)

---

**Built from scratch with Node.js** â€¢ Production-ready â€¢ Well-documented â€¢ Feature-complete